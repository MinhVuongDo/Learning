{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V81aLMrk6wrK",
        "outputId": "bf3e721e-8919-4d44-cac4-e181d924f885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwthjrXd645x",
        "outputId": "e014e70c-dae5-4c96-87b1-9aa26ccb0827"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 43 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 28.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845514 sha256=fb304feb3b418687e50d5fcf6346a86ee3c65d43a393bf2f249c81f505ec7b82\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('dataApp').getOrCreate()"
      ],
      "metadata": {
        "id": "L7km4Unt69QN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User Defined Functions"
      ],
      "metadata": {
        "id": "gWSrVpfq7IHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import LongType\n",
        "\n",
        "# Create cubed function\n",
        "def cubed(s):\n",
        "  return s * s * s\n",
        "\n",
        "# Register UDF\n",
        "spark.udf.register(\"cubed\", cubed, LongType())\n",
        "\n",
        "# Generate temporary view\n",
        "spark.range(1, 9).createOrReplaceTempView(\"udf_test\")"
      ],
      "metadata": {
        "id": "LMlT1j837DnB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT id, cubed(id) AS id_cubed FROM udf_test\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xap78V0a7F5T",
        "outputId": "9a946088-62ff-465b-f28a-3a09af4f1596"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|id_cubed|\n",
            "+---+--------+\n",
            "|  1|       1|\n",
            "|  2|       8|\n",
            "|  3|      27|\n",
            "|  4|      64|\n",
            "|  5|     125|\n",
            "|  6|     216|\n",
            "|  7|     343|\n",
            "|  8|     512|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using pandas dataframe"
      ],
      "metadata": {
        "id": "d07R1-fY7szg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import col, pandas_udf\n",
        "from pyspark.sql.types import LongType\n",
        "\n",
        "# Declare the cubed function \n",
        "def cubed(a: pd.Series) -> pd.Series:\n",
        "    return a * a * a\n",
        "\n",
        "# Create the pandas UDF for the cubed function \n",
        "cubed_udf = pandas_udf(cubed, returnType=LongType())"
      ],
      "metadata": {
        "id": "wey5c-hv7OJK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Pandas series\n",
        "x = pd.Series([1, 2, 3])\n",
        "\n",
        "# The function for a pandas_udf executed with local Pandas data\n",
        "print(cubed(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03LwCmf_7YFO",
        "outputId": "876ce026-275c-47d4-8306-ffc1dca56f80"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     1\n",
            "1     8\n",
            "2    27\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Spark DataFrame"
      ],
      "metadata": {
        "id": "0VWT1w7X70GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark DataFrame\n",
        "df = spark.range(1, 4)\n",
        "\n",
        "# Execute function as a Spark vectorized UDF\n",
        "df.select(\"id\", cubed_udf(col(\"id\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK7Kv89Q7a9A",
        "outputId": "c3c65946-ae7c-4b4e-80f6-ed5df1cb2ed1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "| id|cubed(id)|\n",
            "+---+---------+\n",
            "|  1|        1|\n",
            "|  2|        8|\n",
            "|  3|       27|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an array dataset\n",
        "arrayData = [[1, (1, 2, 3)], [2, (2, 3, 4)], [3, (3, 4, 5)]]\n",
        "\n",
        "# Create schema\n",
        "from pyspark.sql.types import *\n",
        "arraySchema = (StructType([\n",
        "      StructField(\"id\", IntegerType(), True), \n",
        "      StructField(\"values\", ArrayType(IntegerType()), True)\n",
        "      ]))\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(spark.sparkContext.parallelize(arrayData), arraySchema)\n",
        "df.createOrReplaceTempView(\"table\")\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkyZrCUH7eyy",
        "outputId": "12f4173c-588a-4401-e965-d2e1c8197b7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- values: array (nullable = true)\n",
            " |    |-- element: integer (containsNull = true)\n",
            "\n",
            "+---+---------+\n",
            "| id|   values|\n",
            "+---+---------+\n",
            "|  1|[1, 2, 3]|\n",
            "|  2|[2, 3, 4]|\n",
            "|  3|[3, 4, 5]|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT id, collect_list(value + 1) AS newValues\n",
        "  FROM  (SELECT id, explode(values) AS value\n",
        "        FROM table) x\n",
        " GROUP BY id\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgpT905Q79sh",
        "outputId": "f88c44b2-c486-45ac-a1e3-84160187dab0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "| id|newValues|\n",
            "+---+---------+\n",
            "|  1|[2, 3, 4]|\n",
            "|  3|[4, 5, 6]|\n",
            "|  2|[3, 4, 5]|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#User Defined Function"
      ],
      "metadata": {
        "id": "UV63ugEQ8qA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.types import ArrayType\n",
        "\n",
        "# Create UDF\n",
        "def addOne(values):\n",
        "  return [value + 1 for value in values]\n",
        "\n",
        "# Register UDF\n",
        "spark.udf.register(\"plusOneIntPy\", addOne, ArrayType(IntegerType()))  \n",
        "\n",
        "# Query data\n",
        "spark.sql(\"SELECT id, plusOneIntPy(values) AS values FROM table\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7VYUvjm8OzA",
        "outputId": "b634ee6d-b4a7-4b08-ace9-02bcfd7ab561"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "| id|   values|\n",
            "+---+---------+\n",
            "|  1|[2, 3, 4]|\n",
            "|  2|[3, 4, 5]|\n",
            "|  3|[4, 5, 6]|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Higher-Order Functions"
      ],
      "metadata": {
        "id": "3Egorq-v8uHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "schema = StructType([StructField(\"celsius\", ArrayType(IntegerType()))])\n",
        "\n",
        "t_list = [[35, 36, 32, 30, 40, 42, 38]], [[31, 32, 34, 55, 56]]\n",
        "t_c = spark.createDataFrame(t_list, schema)\n",
        "t_c.createOrReplaceTempView(\"tC\")\n",
        "\n",
        "# Show the DataFrame\n",
        "t_c.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC3CXQvM8QWe",
        "outputId": "51ec445d-3435-4f06-d091-3649e6f4b31c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             celsius|\n",
            "+--------------------+\n",
            "|[35, 36, 32, 30, ...|\n",
            "|[31, 32, 34, 55, 56]|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transform"
      ],
      "metadata": {
        "id": "BFTgKUeO9tPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT celsius, transform(celsius, t -> ((t * 9) div 5) + 32) as fahrenheit FROM tC\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04CxFO3B8ZCW",
        "outputId": "b090c478-55be-4388-a594-9cf097de73c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|             celsius|          fahrenheit|\n",
            "+--------------------+--------------------+\n",
            "|[35, 36, 32, 30, ...|[95, 96, 89, 86, ...|\n",
            "|[31, 32, 34, 55, 56]|[87, 89, 93, 131,...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Filter"
      ],
      "metadata": {
        "id": "1Np4K4ck9vnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter temperatures > 38C for array of temperatures\n",
        "spark.sql(\"\"\"SELECT celsius, filter(celsius, t -> t > 38) as high FROM tC\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARWxz7aW8ahv",
        "outputId": "fad48749-a142-4745-d463-19b7a5dc8b5c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+\n",
            "|             celsius|    high|\n",
            "+--------------------+--------+\n",
            "|[35, 36, 32, 30, ...|[40, 42]|\n",
            "|[31, 32, 34, 55, 56]|[55, 56]|\n",
            "+--------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exists"
      ],
      "metadata": {
        "id": "_SdMgyhq92Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT celsius, exists(celsius, t -> t = 38) as threshold\n",
        "FROM tC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqNn_5tk90V-",
        "outputId": "c5e4994a-34c9-4d90-9459-777ecddf4eff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|             celsius|threshold|\n",
            "+--------------------+---------+\n",
            "|[35, 36, 32, 30, ...|     true|\n",
            "|[31, 32, 34, 55, 56]|    false|\n",
            "+--------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reduce"
      ],
      "metadata": {
        "id": "19uqdOTl99fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT celsius, \n",
        "       reduce(\n",
        "          celsius, \n",
        "          0, \n",
        "          (t, acc) -> t + acc, \n",
        "          acc -> (acc div size(celsius) * 9 div 5) + 32\n",
        "        ) as avgFahrenheit \n",
        "  FROM tC\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "id": "xQO2E5MO9-0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# Set File Paths\n",
        "delays_path = \"/content/drive/MyDrive/Colab Notebooks/data/flights/departuredelays.csv\"\n",
        "airports_path = \"/content/drive/MyDrive/Colab Notebooks/data/flights/airport-codes-na.txt\"\n",
        "\n",
        "# Obtain airports dataset\n",
        "airports = spark.read.options(header=\"true\", inferSchema=\"true\", sep=\"\\t\").csv(airports_path)\n",
        "airports.createOrReplaceTempView(\"airports_na\")\n",
        "\n",
        "# Obtain departure Delays data\n",
        "delays = spark.read.options(header=\"true\").csv(delays_path)\n",
        "delays = (delays\n",
        "          .withColumn(\"delay\", expr(\"CAST(delay as INT) as delay\"))\n",
        "          .withColumn(\"distance\", expr(\"CAST(distance as INT) as distance\")))\n",
        "\n",
        "delays.createOrReplaceTempView(\"departureDelays\")\n",
        "\n",
        "# Create temporary small table\n",
        "foo = delays.filter(expr(\"\"\"\n",
        "            origin == 'SEA' AND \n",
        "            destination == 'SFO' AND \n",
        "            date like '01010%' AND \n",
        "            delay > 0\"\"\"))\n",
        "\n",
        "foo.createOrReplaceTempView(\"foo\")"
      ],
      "metadata": {
        "id": "4Vq3NEXY-PUY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM airports_na LIMIT 10\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27yGeym3-dF5",
        "outputId": "4ea0b2e1-c43b-40b7-903f-4bd020691140"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+-------+----+\n",
            "|       City|State|Country|IATA|\n",
            "+-----------+-----+-------+----+\n",
            "| Abbotsford|   BC| Canada| YXX|\n",
            "|   Aberdeen|   SD|    USA| ABR|\n",
            "|    Abilene|   TX|    USA| ABI|\n",
            "|      Akron|   OH|    USA| CAK|\n",
            "|    Alamosa|   CO|    USA| ALS|\n",
            "|     Albany|   GA|    USA| ABY|\n",
            "|     Albany|   NY|    USA| ALB|\n",
            "|Albuquerque|   NM|    USA| ABQ|\n",
            "| Alexandria|   LA|    USA| AEX|\n",
            "|  Allentown|   PA|    USA| ABE|\n",
            "+-----------+-----+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM airports_na LIMIT 10\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wpvcwkZ-f87",
        "outputId": "1f3bc2ca-37aa-44e2-e65a-9028ac7ad283"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+-------+----+\n",
            "|       City|State|Country|IATA|\n",
            "+-----------+-----+-------+----+\n",
            "| Abbotsford|   BC| Canada| YXX|\n",
            "|   Aberdeen|   SD|    USA| ABR|\n",
            "|    Abilene|   TX|    USA| ABI|\n",
            "|      Akron|   OH|    USA| CAK|\n",
            "|    Alamosa|   CO|    USA| ALS|\n",
            "|     Albany|   GA|    USA| ABY|\n",
            "|     Albany|   NY|    USA| ALB|\n",
            "|Albuquerque|   NM|    USA| ABQ|\n",
            "| Alexandria|   LA|    USA| AEX|\n",
            "|  Allentown|   PA|    USA| ABE|\n",
            "+-----------+-----+-------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unions"
      ],
      "metadata": {
        "id": "FB5hqWLG-lM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Union two tables\n",
        "bar = delays.union(foo)\n",
        "bar.createOrReplaceTempView(\"bar\")\n",
        "bar.filter(expr(\"origin == 'SEA' AND destination == 'SFO' AND date LIKE '01010%' AND delay > 0\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvoTHgiZ-qYJ",
        "outputId": "f3b173ad-ef15-4e73-b831-260077125087"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+--------+------+-----------+\n",
            "|    date|delay|distance|origin|destination|\n",
            "+--------+-----+--------+------+-----------+\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "+--------+-----+--------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT * \n",
        "FROM bar \n",
        "WHERE origin = 'SEA' \n",
        "   AND destination = 'SFO' \n",
        "   AND date LIKE '01010%' \n",
        "   AND delay > 0\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--P-G3BB-s2M",
        "outputId": "8caad795-85d4-4414-89b8-dfaba381fa38"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+--------+------+-----------+\n",
            "|    date|delay|distance|origin|destination|\n",
            "+--------+-----+--------+------+-----------+\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "|01010710|   31|     590|   SEA|        SFO|\n",
            "|01010955|  104|     590|   SEA|        SFO|\n",
            "|01010730|    5|     590|   SEA|        SFO|\n",
            "+--------+-----+--------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Joins"
      ],
      "metadata": {
        "id": "LZe4f4Ip-ztX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foo.join(\n",
        "  airports, \n",
        "  airports.IATA == foo.origin\n",
        ").select(\"City\", \"State\", \"date\", \"delay\", \"distance\", \"destination\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVZZ2zHp-xvC",
        "outputId": "d43b970c-c6b7-4409-9a81-6dac918d9fd0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+--------+-----+--------+-----------+\n",
            "|   City|State|    date|delay|distance|destination|\n",
            "+-------+-----+--------+-----+--------+-----------+\n",
            "|Seattle|   WA|01010710|   31|     590|        SFO|\n",
            "|Seattle|   WA|01010955|  104|     590|        SFO|\n",
            "|Seattle|   WA|01010730|    5|     590|        SFO|\n",
            "+-------+-----+--------+-----+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT a.City, a.State, f.date, f.delay, f.distance, f.destination \n",
        "  FROM foo f\n",
        "  JOIN airports_na a\n",
        "    ON a.IATA = f.origin\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sheAHAqb-5bp",
        "outputId": "38350030-6fa6-45f9-a913-4938405782ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+--------+-----+--------+-----------+\n",
            "|   City|State|    date|delay|distance|destination|\n",
            "+-------+-----+--------+-----+--------+-----------+\n",
            "|Seattle|   WA|01010710|   31|     590|        SFO|\n",
            "|Seattle|   WA|01010955|  104|     590|        SFO|\n",
            "|Seattle|   WA|01010730|    5|     590|        SFO|\n",
            "+-------+-----+--------+-----+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Windowing Functions"
      ],
      "metadata": {
        "id": "pitr_NoN--ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"DROP TABLE IF EXISTS departureDelaysWindow\")\n",
        "spark.sql(\"\"\"\n",
        "CREATE TABLE departureDelaysWindow AS\n",
        "SELECT origin, destination, sum(delay) as TotalDelays \n",
        "  FROM departureDelays \n",
        " WHERE origin IN ('SEA', 'SFO', 'JFK') \n",
        "   AND destination IN ('SEA', 'SFO', 'JFK', 'DEN', 'ORD', 'LAX', 'ATL') \n",
        " GROUP BY origin, destination\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"\"\"SELECT * FROM departureDelaysWindow\"\"\").show()"
      ],
      "metadata": {
        "id": "vRE4vhYA_AGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT origin, destination, sum(TotalDelays) as TotalDelays\n",
        " FROM departureDelaysWindow\n",
        "WHERE origin = 'SEA'\n",
        "GROUP BY origin, destination\n",
        "ORDER BY sum(TotalDelays) DESC\n",
        "LIMIT 3\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "Dqw1965f_Wmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT origin, destination, TotalDelays, rank \n",
        "  FROM ( \n",
        "     SELECT origin, destination, TotalDelays, dense_rank() \n",
        "       OVER (PARTITION BY origin ORDER BY TotalDelays DESC) as rank \n",
        "       FROM departureDelaysWindow\n",
        "  ) t \n",
        " WHERE rank <= 3\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "nC-6EKFB_ldv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modifications"
      ],
      "metadata": {
        "id": "uiiTh_BO_rVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding New Columns"
      ],
      "metadata": {
        "id": "ul19_0dH_wQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foo2 = foo.withColumn(\"status\", expr(\"CASE WHEN delay <= 10 THEN 'On-time' ELSE 'Delayed' END\"))\n",
        "foo2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPG5CGuA_qN2",
        "outputId": "2e792935-626b-49f0-f533-d29359d1681d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+--------+------+-----------+-------+\n",
            "|    date|delay|distance|origin|destination| status|\n",
            "+--------+-----+--------+------+-----------+-------+\n",
            "|01010710|   31|     590|   SEA|        SFO|Delayed|\n",
            "|01010955|  104|     590|   SEA|        SFO|Delayed|\n",
            "|01010730|    5|     590|   SEA|        SFO|On-time|\n",
            "+--------+-----+--------+------+-----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT *, CASE WHEN delay <= 10 THEN 'On-time' ELSE 'Delayed' END AS status FROM foo\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c485FTpR_zSW",
        "outputId": "22dc510d-72d7-4c29-c919-63058eae2b06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+--------+------+-----------+-------+\n",
            "|    date|delay|distance|origin|destination| status|\n",
            "+--------+-----+--------+------+-----------+-------+\n",
            "|01010710|   31|     590|   SEA|        SFO|Delayed|\n",
            "|01010955|  104|     590|   SEA|        SFO|Delayed|\n",
            "|01010730|    5|     590|   SEA|        SFO|On-time|\n",
            "+--------+-----+--------+------+-----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dropping Columns"
      ],
      "metadata": {
        "id": "JzJhnp8B_5CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foo3 = foo2.drop(\"delay\")\n",
        "foo3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYFCctkT_6gG",
        "outputId": "c391b0df-d23e-48d9-fbd3-722544d9e0ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+-----------+-------+\n",
            "|    date|distance|origin|destination| status|\n",
            "+--------+--------+------+-----------+-------+\n",
            "|01010710|     590|   SEA|        SFO|Delayed|\n",
            "|01010955|     590|   SEA|        SFO|Delayed|\n",
            "|01010730|     590|   SEA|        SFO|On-time|\n",
            "+--------+--------+------+-----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Renaming Columns"
      ],
      "metadata": {
        "id": "pYAgp0l7__BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foo4 = foo3.withColumnRenamed(\"status\", \"flight_status\")\n",
        "foo4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALAW8gPo_86_",
        "outputId": "2ac07fef-6a65-40f5-c9d1-651e413a605e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+-----------+-------------+\n",
            "|    date|distance|origin|destination|flight_status|\n",
            "+--------+--------+------+-----------+-------------+\n",
            "|01010710|     590|   SEA|        SFO|      Delayed|\n",
            "|01010955|     590|   SEA|        SFO|      Delayed|\n",
            "|01010730|     590|   SEA|        SFO|      On-time|\n",
            "+--------+--------+------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pivoting"
      ],
      "metadata": {
        "id": "nSeRs7U_AqY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT destination, CAST(SUBSTRING(date, 0, 2) AS int) AS month, delay FROM departureDelays WHERE origin = 'SEA'\"\"\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3xeVjUNALdy",
        "outputId": "0b8efcc3-11b2-41a7-f7da-6b206901398f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+-----+\n",
            "|destination|month|delay|\n",
            "+-----------+-----+-----+\n",
            "|        ORD|    1|   92|\n",
            "|        JFK|    1|   -7|\n",
            "|        DFW|    1|   -5|\n",
            "|        MIA|    1|   -3|\n",
            "|        DFW|    1|   -3|\n",
            "|        DFW|    1|    1|\n",
            "|        ORD|    1|  -10|\n",
            "|        DFW|    1|   -6|\n",
            "|        DFW|    1|   -2|\n",
            "|        ORD|    1|   -3|\n",
            "+-----------+-----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT * FROM (\n",
        "SELECT destination, CAST(SUBSTRING(date, 0, 2) AS int) AS month, delay \n",
        "  FROM departureDelays WHERE origin = 'SEA' \n",
        ") \n",
        "PIVOT (\n",
        "  CAST(AVG(delay) AS DECIMAL(4, 2)) as AvgDelay, MAX(delay) as MaxDelay\n",
        "  FOR month IN (1 JAN, 2 FEB, 3 MAR)\n",
        ")\n",
        "ORDER BY destination\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuyNoHI2AxAZ",
        "outputId": "1c231825-5e72-4ff0-f365-05b9482a6f35"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+------------+------------+------------+------------+------------+\n",
            "|destination|JAN_AvgDelay|JAN_MaxDelay|FEB_AvgDelay|FEB_MaxDelay|MAR_AvgDelay|MAR_MaxDelay|\n",
            "+-----------+------------+------------+------------+------------+------------+------------+\n",
            "|        ABQ|       19.86|         316|       11.42|          69|       11.47|          74|\n",
            "|        ANC|        4.44|         149|        7.90|         141|        5.10|         187|\n",
            "|        ATL|       11.98|         397|        7.73|         145|        6.53|         109|\n",
            "|        AUS|        3.48|          50|       -0.21|          18|        4.03|          61|\n",
            "|        BOS|        7.84|         110|       14.58|         152|        7.78|         119|\n",
            "|        BUR|       -2.03|          56|       -1.89|          78|        2.01|         108|\n",
            "|        CLE|       16.00|          27|        null|        null|        null|        null|\n",
            "|        CLT|        2.53|          41|       12.96|         228|        5.16|         110|\n",
            "|        COS|        5.32|          82|       12.18|         203|        9.74|         205|\n",
            "|        CVG|       -0.50|           4|        null|        null|        null|        null|\n",
            "|        DCA|       -1.15|          50|        0.07|          34|        5.73|         199|\n",
            "|        DEN|       13.13|         425|       12.95|         625|        7.48|         231|\n",
            "|        DFW|        7.95|         247|       12.57|         356|        6.71|         277|\n",
            "|        DTW|        9.18|         107|        3.47|          77|        2.47|          72|\n",
            "|        EWR|        9.63|         236|        5.20|         212|       10.59|         181|\n",
            "|        FAI|        1.84|         160|        4.21|          60|        5.32|          98|\n",
            "|        FAT|        1.36|         119|        5.22|         232|        1.67|          92|\n",
            "|        FLL|        2.94|          54|        3.50|          40|        3.06|          52|\n",
            "|        GEG|        2.28|          63|        2.87|          60|        4.49|          89|\n",
            "|        HDN|       -0.44|          27|       -6.50|           0|       -3.44|          15|\n",
            "+-----------+------------+------------+------------+------------+------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT * FROM (\n",
        "SELECT destination, CAST(SUBSTRING(date, 0, 2) AS int) AS month, delay \n",
        "  FROM departureDelays WHERE origin = 'SEA' \n",
        ") \n",
        "PIVOT (\n",
        "  CAST(AVG(delay) AS DECIMAL(4, 2)) as AvgDelay, MAX(delay) as MaxDelay\n",
        "  FOR month IN (1 JAN, 2 FEB)\n",
        ")\n",
        "ORDER BY destination\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3rvcCojA3tj",
        "outputId": "c2853ae7-fedb-4faf-8764-d9f19d1a73b1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+------------+------------+------------+\n",
            "|destination|JAN_AvgDelay|JAN_MaxDelay|FEB_AvgDelay|FEB_MaxDelay|\n",
            "+-----------+------------+------------+------------+------------+\n",
            "|        ABQ|       19.86|         316|       11.42|          69|\n",
            "|        ANC|        4.44|         149|        7.90|         141|\n",
            "|        ATL|       11.98|         397|        7.73|         145|\n",
            "|        AUS|        3.48|          50|       -0.21|          18|\n",
            "|        BOS|        7.84|         110|       14.58|         152|\n",
            "|        BUR|       -2.03|          56|       -1.89|          78|\n",
            "|        CLE|       16.00|          27|        null|        null|\n",
            "|        CLT|        2.53|          41|       12.96|         228|\n",
            "|        COS|        5.32|          82|       12.18|         203|\n",
            "|        CVG|       -0.50|           4|        null|        null|\n",
            "|        DCA|       -1.15|          50|        0.07|          34|\n",
            "|        DEN|       13.13|         425|       12.95|         625|\n",
            "|        DFW|        7.95|         247|       12.57|         356|\n",
            "|        DTW|        9.18|         107|        3.47|          77|\n",
            "|        EWR|        9.63|         236|        5.20|         212|\n",
            "|        FAI|        1.84|         160|        4.21|          60|\n",
            "|        FAT|        1.36|         119|        5.22|         232|\n",
            "|        FLL|        2.94|          54|        3.50|          40|\n",
            "|        GEG|        2.28|          63|        2.87|          60|\n",
            "|        HDN|       -0.44|          27|       -6.50|           0|\n",
            "+-----------+------------+------------+------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}